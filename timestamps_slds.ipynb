{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40e8835a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages (from pytesseract) (25.0)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages (from pytesseract) (11.3.0)\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.13\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d808e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\hayk_\\.conda\\envs\\thesis\\Lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dask 2025.5.1 requires toolz>=0.10.0, which is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting easyocr\n",
      "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\hayk_\\.conda\\envs\\thesis\\lib\\site-packages (from easyocr) (1.12.0+cu113)\n",
      "Collecting torchvision>=0.5 (from easyocr)\n",
      "  Downloading torchvision-0.23.0-cp310-cp310-win_amd64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\hayk_\\.conda\\envs\\thesis\\lib\\site-packages (from easyocr) (4.12.0.88)\n",
      "Requirement already satisfied: scipy in c:\\users\\hayk_\\.conda\\envs\\thesis\\lib\\site-packages (from easyocr) (1.13.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hayk_\\.conda\\envs\\thesis\\lib\\site-packages (from easyocr) (2.0.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hayk_\\.conda\\envs\\thesis\\lib\\site-packages (from easyocr) (10.3.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\hayk_\\.conda\\envs\\thesis\\lib\\site-packages (from easyocr) (0.25.2)\n",
      "Collecting python-bidi (from easyocr)\n",
      "  Downloading python_bidi-0.6.6-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting PyYAML (from easyocr)\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting Shapely (from easyocr)\n",
      "  Downloading shapely-2.1.1-cp310-cp310-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting pyclipper (from easyocr)\n",
      "  Downloading pyclipper-1.3.0.post6-cp310-cp310-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting ninja (from easyocr)\n",
      "  Downloading ninja-1.11.1.4-py3-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting torch (from easyocr)\n",
      "  Downloading torch-2.8.0-cp310-cp310-win_amd64.whl.metadata (30 kB)\n",
      "Collecting filelock (from torch->easyocr)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hayk_\\.conda\\envs\\thesis\\lib\\site-packages (from torch->easyocr) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hayk_\\.conda\\envs\\thesis\\lib\\site-packages (from torch->easyocr) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hayk_\\.conda\\envs\\thesis\\lib\\site-packages (from torch->easyocr) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hayk_\\.conda\\envs\\thesis\\lib\\site-packages (from torch->easyocr) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hayk_\\.conda\\envs\\thesis\\lib\\site-packages (from torch->easyocr) (2025.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hayk_\\.conda\\envs\\thesis\\lib\\site-packages (from sympy>=1.13.3->torch->easyocr) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hayk_\\.conda\\envs\\thesis\\lib\\site-packages (from jinja2->torch->easyocr) (2.1.5)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\hayk_\\.conda\\envs\\thesis\\lib\\site-packages (from scikit-image->easyocr) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\hayk_\\.conda\\envs\\thesis\\lib\\site-packages (from scikit-image->easyocr) (2025.5.10)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\hayk_\\.conda\\envs\\thesis\\lib\\site-packages (from scikit-image->easyocr) (25.0)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\hayk_\\.conda\\envs\\thesis\\lib\\site-packages (from scikit-image->easyocr) (0.4)\n",
      "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
      "   ---------------------------------------- 2.9/2.9 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.23.0-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 1.6/1.6 MB 3.0 MB/s eta 0:00:00\n",
      "Downloading torch-2.8.0-cp310-cp310-win_amd64.whl (241.4 MB)\n",
      "   ---------------------------------------- 241.4/241.4 MB 2.4 MB/s eta 0:00:00\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading ninja-1.11.1.4-py3-none-win_amd64.whl (296 kB)\n",
      "Downloading pyclipper-1.3.0.post6-cp310-cp310-win_amd64.whl (110 kB)\n",
      "Downloading python_bidi-0.6.6-cp310-cp310-win_amd64.whl (160 kB)\n",
      "Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Downloading shapely-2.1.1-cp310-cp310-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 1.7/1.7 MB 3.4 MB/s eta 0:00:00\n",
      "Installing collected packages: python-bidi, pyclipper, Shapely, PyYAML, ninja, filelock, torch, torchvision, easyocr\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.0+cu113\n",
      "    Uninstalling torch-1.12.0+cu113:\n",
      "      Successfully uninstalled torch-1.12.0+cu113\n",
      "\n",
      "Successfully installed PyYAML-6.0.2 Shapely-2.1.1 easyocr-1.7.2 filelock-3.18.0 ninja-1.11.1.4 pyclipper-1.3.0.post6 python-bidi-0.6.6 torch-2.8.0 torchvision-0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f23df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8b392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a858a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: numpy in c:\\users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall numpy\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a9e886",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _multiarray_umath: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _multiarray_umath: The specified module could not be found."
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy._core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytesseract\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\pytesseract\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa: F401\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytesseract\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ALTONotSupported\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytesseract\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_languages\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytesseract\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_tesseract_version\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\pytesseract\\pytesseract.py:42\u001b[0m\n\u001b[0;32m     39\u001b[0m     numpy_installed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     pandas_installed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\pandas\\__init__.py:61\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     ArrowDtype,\n\u001b[0;32m     64\u001b[0m     Int8Dtype,\n\u001b[0;32m     65\u001b[0m     Int16Dtype,\n\u001b[0;32m     66\u001b[0m     Int32Dtype,\n\u001b[0;32m     67\u001b[0m     Int64Dtype,\n\u001b[0;32m     68\u001b[0m     UInt8Dtype,\n\u001b[0;32m     69\u001b[0m     UInt16Dtype,\n\u001b[0;32m     70\u001b[0m     UInt32Dtype,\n\u001b[0;32m     71\u001b[0m     UInt64Dtype,\n\u001b[0;32m     72\u001b[0m     Float32Dtype,\n\u001b[0;32m     73\u001b[0m     Float64Dtype,\n\u001b[0;32m     74\u001b[0m     CategoricalDtype,\n\u001b[0;32m     75\u001b[0m     PeriodDtype,\n\u001b[0;32m     76\u001b[0m     IntervalDtype,\n\u001b[0;32m     77\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     78\u001b[0m     StringDtype,\n\u001b[0;32m     79\u001b[0m     BooleanDtype,\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     NA,\n\u001b[0;32m     82\u001b[0m     isna,\n\u001b[0;32m     83\u001b[0m     isnull,\n\u001b[0;32m     84\u001b[0m     notna,\n\u001b[0;32m     85\u001b[0m     notnull,\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     Index,\n\u001b[0;32m     88\u001b[0m     CategoricalIndex,\n\u001b[0;32m     89\u001b[0m     RangeIndex,\n\u001b[0;32m     90\u001b[0m     MultiIndex,\n\u001b[0;32m     91\u001b[0m     IntervalIndex,\n\u001b[0;32m     92\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     93\u001b[0m     DatetimeIndex,\n\u001b[0;32m     94\u001b[0m     PeriodIndex,\n\u001b[0;32m     95\u001b[0m     IndexSlice,\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     NaT,\n\u001b[0;32m     98\u001b[0m     Period,\n\u001b[0;32m     99\u001b[0m     period_range,\n\u001b[0;32m    100\u001b[0m     Timedelta,\n\u001b[0;32m    101\u001b[0m     timedelta_range,\n\u001b[0;32m    102\u001b[0m     Timestamp,\n\u001b[0;32m    103\u001b[0m     date_range,\n\u001b[0;32m    104\u001b[0m     bdate_range,\n\u001b[0;32m    105\u001b[0m     Interval,\n\u001b[0;32m    106\u001b[0m     interval_range,\n\u001b[0;32m    107\u001b[0m     DateOffset,\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     to_numeric,\n\u001b[0;32m    110\u001b[0m     to_datetime,\n\u001b[0;32m    111\u001b[0m     to_timedelta,\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     Flags,\n\u001b[0;32m    114\u001b[0m     Grouper,\n\u001b[0;32m    115\u001b[0m     factorize,\n\u001b[0;32m    116\u001b[0m     unique,\n\u001b[0;32m    117\u001b[0m     value_counts,\n\u001b[0;32m    118\u001b[0m     NamedAgg,\n\u001b[0;32m    119\u001b[0m     array,\n\u001b[0;32m    120\u001b[0m     Categorical,\n\u001b[0;32m    121\u001b[0m     set_eng_float_format,\n\u001b[0;32m    122\u001b[0m     Series,\n\u001b[0;32m    123\u001b[0m     DataFrame,\n\u001b[0;32m    124\u001b[0m )\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hayk_\\.conda\\envs\\youtube\\lib\\site-packages\\pandas\\_libs\\__init__.py:17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Below imports needs to happen first to ensure pandas top level\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# module gets monkeypatched with the pandas_datetime_CAPI\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# see pandas_datetime_exec in pd_datetime.c\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: numpy._core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "# Install required packages if not already installed\n",
    "# !pip install opencv-python pytesseract pillow difflib\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "from datetime import timedelta\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1bc280",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlideDetector:\n",
    "    def __init__(self, tesseract_path=None, similarity_threshold=0.8, frame_interval=2.0):\n",
    "        \"\"\"\n",
    "        Initialize the SlideDetector\n",
    "        \n",
    "        Args:\n",
    "            tesseract_path (str): Path to tesseract executable (if not in PATH)\n",
    "            similarity_threshold (float): Threshold for determining if slides are similar (0-1)\n",
    "            frame_interval (float): Interval in seconds between frame extractions\n",
    "        \"\"\"\n",
    "        if tesseract_path:\n",
    "            pytesseract.pytesseract.tesseract_cmd = tesseract_path\n",
    "        \n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.frame_interval = frame_interval\n",
    "        self.slide_changes = []\n",
    "        \n",
    "    def extract_text_from_frame(self, frame, roi=None):\n",
    "        \"\"\"\n",
    "        Extract text from a video frame using OCR\n",
    "        \n",
    "        Args:\n",
    "            frame: OpenCV frame\n",
    "            roi: Region of interest (x, y, w, h) to focus OCR on specific area\n",
    "        \n",
    "        Returns:\n",
    "            str: Extracted text\n",
    "        \"\"\"\n",
    "        # Convert frame to PIL Image\n",
    "        if roi:\n",
    "            x, y, w, h = roi\n",
    "            frame = frame[y:y+h, x:x+w]\n",
    "        \n",
    "        # Convert BGR to RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_image = Image.fromarray(rgb_frame)\n",
    "        \n",
    "        # Use OCR to extract text\n",
    "        try:\n",
    "            text = pytesseract.image_to_string(pil_image, config='--psm 6')\n",
    "            return text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"OCR Error: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"\n",
    "        Clean extracted text by removing special characters and normalizing\n",
    "        \"\"\"\n",
    "        # Remove extra whitespace and special characters\n",
    "        cleaned = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "        return cleaned.lower()\n",
    "    \n",
    "    def calculate_text_similarity(self, text1, text2):\n",
    "        \"\"\"\n",
    "        Calculate similarity between two text strings\n",
    "        \n",
    "        Returns:\n",
    "            float: Similarity score (0-1)\n",
    "        \"\"\"\n",
    "        if not text1 or not text2:\n",
    "            return 0.0\n",
    "        \n",
    "        cleaned_text1 = self.clean_text(text1)\n",
    "        cleaned_text2 = self.clean_text(text2)\n",
    "        \n",
    "        return SequenceMatcher(None, cleaned_text1, cleaned_text2).ratio()\n",
    "    \n",
    "    def extract_slide_title(self, text):\n",
    "        \"\"\"\n",
    "        Extract the most likely slide title from OCR text\n",
    "        Assumes title is usually the first few lines or largest text\n",
    "        \"\"\"\n",
    "        lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "        if not lines:\n",
    "            return \"Untitled Slide\"\n",
    "        \n",
    "        # Take the first non-empty line as title, or combine first few short lines\n",
    "        title_parts = []\n",
    "        for line in lines[:3]:  # Check first 3 lines\n",
    "            if len(line) > 3 and len(line) < 100:  # Reasonable title length\n",
    "                title_parts.append(line)\n",
    "            if len(' '.join(title_parts)) > 50:  # Don't make title too long\n",
    "                break\n",
    "        \n",
    "        title = ' '.join(title_parts) if title_parts else lines[0]\n",
    "        return title[:100]  # Limit title length\n",
    "    \n",
    "    def seconds_to_timestamp(self, seconds):\n",
    "        \"\"\"\n",
    "        Convert seconds to MM:SS or HH:MM:SS format\n",
    "        \"\"\"\n",
    "        td = timedelta(seconds=int(seconds))\n",
    "        total_seconds = int(td.total_seconds())\n",
    "        hours = total_seconds // 3600\n",
    "        minutes = (total_seconds % 3600) // 60\n",
    "        seconds = total_seconds % 60\n",
    "        \n",
    "        if hours > 0:\n",
    "            return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "        else:\n",
    "            return f\"{minutes:02d}:{seconds:02d}\"\n",
    "    \n",
    "    def process_video(self, video_path, roi=None, output_file=None):\n",
    "        \"\"\"\n",
    "        Process a single video file to detect slide changes\n",
    "        \n",
    "        Args:\n",
    "            video_path (str): Path to video file\n",
    "            roi (tuple): Region of interest (x, y, w, h) for title area\n",
    "            output_file (str): Optional output file path for results\n",
    "        \n",
    "        Returns:\n",
    "            list: List of dictionaries containing timestamp and slide title\n",
    "        \"\"\"\n",
    "        if not os.path.exists(video_path):\n",
    "            raise FileNotFoundError(f\"Video file not found: {video_path}\")\n",
    "        \n",
    "        print(f\"Processing video: {os.path.basename(video_path)}\")\n",
    "        \n",
    "        # Open video\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(f\"Could not open video file: {video_path}\")\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = total_frames / fps\n",
    "        \n",
    "        print(f\"Video duration: {self.seconds_to_timestamp(duration)}\")\n",
    "        print(f\"FPS: {fps:.2f}\")\n",
    "        \n",
    "        self.slide_changes = []\n",
    "        previous_text = \"\"\n",
    "        frame_number = 0\n",
    "        \n",
    "        # Process frames at specified intervals\n",
    "        while True:\n",
    "            # Set frame position\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Calculate timestamp\n",
    "            timestamp_seconds = frame_number / fps\n",
    "            \n",
    "            # Extract text from frame\n",
    "            current_text = self.extract_text_from_frame(frame, roi)\n",
    "            \n",
    "            # Check if this is a new slide\n",
    "            if previous_text:\n",
    "                similarity = self.calculate_text_similarity(previous_text, current_text)\n",
    "                \n",
    "                if similarity < self.similarity_threshold and len(current_text) > 10:\n",
    "                    # New slide detected\n",
    "                    slide_title = self.extract_slide_title(current_text)\n",
    "                    timestamp = self.seconds_to_timestamp(timestamp_seconds)\n",
    "                    \n",
    "                    slide_info = {\n",
    "                        'timestamp': timestamp,\n",
    "                        'timestamp_seconds': timestamp_seconds,\n",
    "                        'slide_title': slide_title,\n",
    "                        'full_text': current_text\n",
    "                    }\n",
    "                    \n",
    "                    self.slide_changes.append(slide_info)\n",
    "                    print(f\"New slide at {timestamp}: {slide_title}\")\n",
    "            else:\n",
    "                # First slide\n",
    "                if len(current_text) > 10:\n",
    "                    slide_title = self.extract_slide_title(current_text)\n",
    "                    timestamp = self.seconds_to_timestamp(timestamp_seconds)\n",
    "                    \n",
    "                    slide_info = {\n",
    "                        'timestamp': timestamp,\n",
    "                        'timestamp_seconds': timestamp_seconds,\n",
    "                        'slide_title': slide_title,\n",
    "                        'full_text': current_text\n",
    "                    }\n",
    "                    \n",
    "                    self.slide_changes.append(slide_info)\n",
    "                    print(f\"First slide at {timestamp}: {slide_title}\")\n",
    "            \n",
    "            previous_text = current_text\n",
    "            \n",
    "            # Move to next frame\n",
    "            frame_number += int(fps * self.frame_interval)\n",
    "            \n",
    "            # Progress indicator\n",
    "            progress = (frame_number / total_frames) * 100\n",
    "            if frame_number % (int(fps * 10)) == 0:  # Print every 10 seconds\n",
    "                print(f\"Progress: {progress:.1f}%\")\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        # Save results if output file specified\n",
    "        if output_file:\n",
    "            self.save_results(output_file, video_path)\n",
    "        \n",
    "        print(f\"\\\\nFound {len(self.slide_changes)} slide changes\")\n",
    "        return self.slide_changes\n",
    "    \n",
    "    def save_results(self, output_file, video_path):\n",
    "        \"\"\"\n",
    "        Save slide detection results to file\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'video_path': video_path,\n",
    "            'video_name': os.path.basename(video_path),\n",
    "            'total_slides': len(self.slide_changes),\n",
    "            'slides': self.slide_changes\n",
    "        }\n",
    "        \n",
    "        # Determine file format based on extension\n",
    "        if output_file.endswith('.json'):\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "        elif output_file.endswith('.csv'):\n",
    "            df = pd.DataFrame(self.slide_changes)\n",
    "            df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "        else:\n",
    "            # Default to text format\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"Video: {os.path.basename(video_path)}\\\\n\")\n",
    "                f.write(f\"Total slides: {len(self.slide_changes)}\\\\n\\\\n\")\n",
    "                for slide in self.slide_changes:\n",
    "                    f.write(f\"{slide['timestamp']} - {slide['slide_title']}\\\\n\")\n",
    "        \n",
    "        print(f\"Results saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de8a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoPlaylistProcessor:\n",
    "    \"\"\"\n",
    "    Process multiple videos in a directory/playlist\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tesseract_path=None, similarity_threshold=0.8, frame_interval=2.0):\n",
    "        self.detector = SlideDetector(tesseract_path, similarity_threshold, frame_interval)\n",
    "        self.supported_formats = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm']\n",
    "    \n",
    "    def find_video_files(self, directory):\n",
    "        \"\"\"\n",
    "        Find all video files in the specified directory\n",
    "        \"\"\"\n",
    "        video_files = []\n",
    "        directory = Path(directory)\n",
    "        \n",
    "        if not directory.exists():\n",
    "            raise FileNotFoundError(f\"Directory not found: {directory}\")\n",
    "        \n",
    "        for file_path in directory.rglob('*'):\n",
    "            if file_path.suffix.lower() in self.supported_formats:\n",
    "                video_files.append(str(file_path))\n",
    "        \n",
    "        return sorted(video_files)\n",
    "    \n",
    "    def process_playlist(self, directory, output_dir=None, roi=None):\n",
    "        \"\"\"\n",
    "        Process all videos in a directory\n",
    "        \n",
    "        Args:\n",
    "            directory (str): Directory containing video files\n",
    "            output_dir (str): Directory to save results (optional)\n",
    "            roi (tuple): Region of interest for slide titles\n",
    "        \n",
    "        Returns:\n",
    "            dict: Results for all videos\n",
    "        \"\"\"\n",
    "        video_files = self.find_video_files(directory)\n",
    "        \n",
    "        if not video_files:\n",
    "            print(f\"No video files found in {directory}\")\n",
    "            return {}\n",
    "        \n",
    "        print(f\"Found {len(video_files)} video files to process\")\n",
    "        \n",
    "        if output_dir:\n",
    "            output_dir = Path(output_dir)\n",
    "            output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        all_results = {}\n",
    "        \n",
    "        for i, video_path in enumerate(video_files, 1):\n",
    "            print(f\"\\\\n{'='*60}\")\n",
    "            print(f\"Processing video {i}/{len(video_files)}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            try:\n",
    "                video_name = Path(video_path).stem\n",
    "                \n",
    "                # Process video\n",
    "                slide_changes = self.detector.process_video(video_path, roi)\n",
    "                \n",
    "                # Save individual results\n",
    "                if output_dir:\n",
    "                    output_file = output_dir / f\"{video_name}_timestamps.json\"\n",
    "                    self.detector.save_results(str(output_file), video_path)\n",
    "                \n",
    "                all_results[video_name] = {\n",
    "                    'path': video_path,\n",
    "                    'slides': slide_changes,\n",
    "                    'total_slides': len(slide_changes)\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {video_path}: {e}\")\n",
    "                all_results[Path(video_path).stem] = {\n",
    "                    'path': video_path,\n",
    "                    'error': str(e),\n",
    "                    'slides': [],\n",
    "                    'total_slides': 0\n",
    "                }\n",
    "        \n",
    "        # Save combined results\n",
    "        if output_dir:\n",
    "            self.save_combined_results(all_results, output_dir / \"all_videos_summary.json\")\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def save_combined_results(self, all_results, output_file):\n",
    "        \"\"\"\n",
    "        Save combined results for all videos\n",
    "        \"\"\"\n",
    "        summary = {\n",
    "            'total_videos': len(all_results),\n",
    "            'successful_videos': len([r for r in all_results.values() if 'error' not in r]),\n",
    "            'total_slides_detected': sum(r['total_slides'] for r in all_results.values()),\n",
    "            'videos': all_results\n",
    "        }\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"\\\\nCombined results saved to: {output_file}\")\n",
    "        \n",
    "        # Also create a simple CSV summary\n",
    "        csv_file = str(output_file).replace('.json', '.csv')\n",
    "        video_summary = []\n",
    "        for video_name, data in all_results.items():\n",
    "            video_summary.append({\n",
    "                'video_name': video_name,\n",
    "                'total_slides': data['total_slides'],\n",
    "                'status': 'success' if 'error' not in data else 'error'\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(video_summary)\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        print(f\"Summary CSV saved to: {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e692085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage and helper functions\n",
    "\n",
    "def auto_detect_title_region(video_path, sample_frames=5):\n",
    "    \"\"\"\n",
    "    Automatically detect the region where slide titles are likely located\n",
    "    by analyzing sample frames\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return None\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Sample frames from different parts of the video\n",
    "    sample_positions = np.linspace(0, total_frames - 1, sample_frames, dtype=int)\n",
    "    \n",
    "    height, width = None, None\n",
    "    \n",
    "    for pos in sample_positions:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, pos)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            height, width = frame.shape[:2]\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    if height and width:\n",
    "        # Assume title is in top 30% of the frame\n",
    "        roi = (0, 0, width, int(height * 0.3))\n",
    "        return roi\n",
    "    \n",
    "    return None\n",
    "\n",
    "def display_sample_detection(video_path, roi=None, sample_time=30):\n",
    "    \"\"\"\n",
    "    Display a sample frame with detected text for debugging\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Could not open video\")\n",
    "        return\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_pos = int(sample_time * fps)\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_pos)\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        detector = SlideDetector()\n",
    "        text = detector.extract_text_from_frame(frame, roi)\n",
    "        title = detector.extract_slide_title(text)\n",
    "        \n",
    "        print(f\"Sample at {sample_time}s:\")\n",
    "        print(f\"Detected title: {title}\")\n",
    "        print(f\"Full text: {text[:200]}...\")\n",
    "        \n",
    "        # Optionally save sample frame\n",
    "        sample_path = f\"sample_frame_{sample_time}s.jpg\"\n",
    "        cv2.imwrite(sample_path, frame)\n",
    "        print(f\"Sample frame saved to: {sample_path}\")\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "# Configuration function\n",
    "def setup_tesseract_windows():\n",
    "    \"\"\"\n",
    "    Setup function for Windows users to configure Tesseract path\n",
    "    \"\"\"\n",
    "    common_paths = [\n",
    "        r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\",\n",
    "        r\"C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe\",\n",
    "        r\"C:\\Users\\{}\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\".format(os.getenv('USERNAME'))\n",
    "    ]\n",
    "    \n",
    "    for path in common_paths:\n",
    "        if os.path.exists(path):\n",
    "            pytesseract.pytesseract.tesseract_cmd = path\n",
    "            print(f\"Tesseract configured at: {path}\")\n",
    "            return path\n",
    "    \n",
    "    print(\"Tesseract not found in common locations.\")\n",
    "    print(\"Please install Tesseract OCR from: https://github.com/UB-Mannheim/tesseract/wiki\")\n",
    "    print(\"Or manually set the path using: pytesseract.pytesseract.tesseract_cmd = 'your_path_here'\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a8df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP AND USAGE EXAMPLE\n",
    "\n",
    "# 1. First, setup Tesseract (required for OCR)\n",
    "print(\"Setting up Tesseract OCR...\")\n",
    "tesseract_path = setup_tesseract_windows()\n",
    "\n",
    "# If tesseract is not found automatically, uncomment and set the path manually:\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b1cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. EXAMPLE: Process a single video\n",
    "\n",
    "# Replace with your video path\n",
    "video_path = r\"The Greatest Portrait Photographer of All Time [WVHw4-62rV4].mp4\"\n",
    "\n",
    "if os.path.exists(video_path):\n",
    "    print(f\"Testing with video: {video_path}\")\n",
    "    \n",
    "    # Test sample detection first\n",
    "    print(\"\\\\nTesting sample detection...\")\n",
    "    display_sample_detection(video_path, sample_time=30)\n",
    "    \n",
    "    # Auto-detect title region\n",
    "    roi = auto_detect_title_region(video_path)\n",
    "    print(f\"\\\\nAuto-detected ROI: {roi}\")\n",
    "    \n",
    "    # Process the video\n",
    "    detector = SlideDetector(\n",
    "        similarity_threshold=0.7,  # Adjust based on your needs (0.5-0.9)\n",
    "        frame_interval=3.0         # Check every 3 seconds\n",
    "    )\n",
    "    \n",
    "    results = detector.process_video(\n",
    "        video_path=video_path,\n",
    "        roi=roi,  # Focus on title area\n",
    "        output_file=\"single_video_results.json\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\\\nDetected {len(results)} slide changes:\")\n",
    "    for slide in results:\n",
    "        print(f\"  {slide['timestamp']} - {slide['slide_title']}\")\n",
    "else:\n",
    "    print(f\"Video file not found: {video_path}\")\n",
    "    print(\"Please update the video_path variable with a valid video file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. EXAMPLE: Process multiple videos in a directory\n",
    "\n",
    "# Replace with your videos directory\n",
    "videos_directory = r\"videos\"  # or your specific path like r\"C:\\Users\\username\\Videos\\Presentations\"\n",
    "\n",
    "processor = VideoPlaylistProcessor(\n",
    "    similarity_threshold=0.7,\n",
    "    frame_interval=3.0\n",
    ")\n",
    "\n",
    "# Check if directory exists and find videos\n",
    "if os.path.exists(videos_directory):\n",
    "    video_files = processor.find_video_files(videos_directory)\n",
    "    print(f\"Found {len(video_files)} video files in {videos_directory}:\")\n",
    "    for i, video in enumerate(video_files, 1):\n",
    "        print(f\"  {i}. {os.path.basename(video)}\")\n",
    "    \n",
    "    if video_files:\n",
    "        # Process all videos\n",
    "        print(f\"\\\\nProcessing all videos...\")\n",
    "        results = processor.process_playlist(\n",
    "            directory=videos_directory,\n",
    "            output_dir=\"slide_detection_results\",  # Results will be saved here\n",
    "            roi=None  # Auto-detect for each video\n",
    "        )\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\\\n{'='*60}\")\n",
    "        print(\"PROCESSING SUMMARY\")\n",
    "        print(f\"{'='*60}\")\n",
    "        total_slides = sum(data['total_slides'] for data in results.values())\n",
    "        successful = len([r for r in results.values() if 'error' not in r])\n",
    "        \n",
    "        print(f\"Videos processed: {len(results)}\")\n",
    "        print(f\"Successful: {successful}\")\n",
    "        print(f\"Total slides detected: {total_slides}\")\n",
    "        \n",
    "        print(\"\\\\nPer video results:\")\n",
    "        for video_name, data in results.items():\n",
    "            if 'error' in data:\n",
    "                print(f\"  ‚ùå {video_name}: ERROR - {data['error']}\")\n",
    "            else:\n",
    "                print(f\"  ‚úÖ {video_name}: {data['total_slides']} slides\")\n",
    "    else:\n",
    "        print(\"No video files found in the directory.\")\n",
    "else:\n",
    "    print(f\"Directory not found: {videos_directory}\")\n",
    "    print(\"Please update the videos_directory variable with the correct path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdc45b7",
   "metadata": {},
   "source": [
    "# YouTube Slide Detection Tool\n",
    "\n",
    "## Overview\n",
    "This tool processes YouTube presentation videos to automatically detect slide changes using OCR (Optical Character Recognition) and outputs timestamps with slide titles.\n",
    "\n",
    "## Features\n",
    "- üé• **Batch Processing**: Process multiple videos in a directory\n",
    "- üîç **OCR Detection**: Extract slide titles using Tesseract OCR\n",
    "- ‚è±Ô∏è **Timestamp Generation**: Accurate timestamps for each slide change\n",
    "- üìä **Multiple Output Formats**: JSON, CSV, and text formats\n",
    "- üéØ **ROI Support**: Focus OCR on specific screen regions for better accuracy\n",
    "- üîß **Configurable**: Adjustable similarity thresholds and processing intervals\n",
    "\n",
    "## Requirements\n",
    "1. **Python packages**: opencv-python, pytesseract, pillow, pandas, numpy\n",
    "2. **Tesseract OCR**: Must be installed separately\n",
    "   - Download from: https://github.com/UB-Mannheim/tesseract/wiki\n",
    "   - Windows installer available\n",
    "\n",
    "## Configuration Tips\n",
    "\n",
    "### Similarity Threshold\n",
    "- **0.5-0.6**: Very sensitive, detects small changes\n",
    "- **0.7-0.8**: Balanced, good for most presentations  \n",
    "- **0.8-0.9**: Less sensitive, only major slide changes\n",
    "\n",
    "### Frame Interval\n",
    "- **1-2 seconds**: More accurate but slower processing\n",
    "- **3-5 seconds**: Faster processing, may miss quick slides\n",
    "- **5+ seconds**: Fast but might miss slides\n",
    "\n",
    "### ROI (Region of Interest)\n",
    "- Use auto-detection or manually specify title area\n",
    "- Format: (x, y, width, height)\n",
    "- Example: (0, 0, 1920, 300) for top 300 pixels of 1920px wide video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c89bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. TROUBLESHOOTING AND ADVANCED USAGE\n",
    "\n",
    "def test_ocr_setup():\n",
    "    \"\"\"Test if OCR is working properly\"\"\"\n",
    "    try:\n",
    "        # Create a simple test image with text\n",
    "        import numpy as np\n",
    "        from PIL import Image, ImageDraw, ImageFont\n",
    "        \n",
    "        # Create test image\n",
    "        img = Image.new('RGB', (400, 100), color='white')\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        draw.text((10, 30), \"Test Slide Title\", fill='black')\n",
    "        \n",
    "        # Convert to array and test OCR\n",
    "        img_array = np.array(img)\n",
    "        text = pytesseract.image_to_string(img_array)\n",
    "        \n",
    "        print(f\"OCR Test Result: '{text.strip()}'\")\n",
    "        \n",
    "        if \"Test\" in text or \"Slide\" in text:\n",
    "            print(\"‚úÖ OCR is working correctly!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"‚ùå OCR might not be working properly\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå OCR Error: {e}\")\n",
    "        return False\n",
    "\n",
    "def optimize_settings_for_video(video_path, test_duration=60):\n",
    "    \"\"\"\n",
    "    Test different settings to find optimal configuration for a specific video\n",
    "    \"\"\"\n",
    "    print(f\"Optimizing settings for: {os.path.basename(video_path)}\")\n",
    "    \n",
    "    if not os.path.exists(video_path):\n",
    "        print(\"Video file not found!\")\n",
    "        return\n",
    "    \n",
    "    # Test different thresholds\n",
    "    thresholds = [0.6, 0.7, 0.8]\n",
    "    intervals = [2.0, 3.0, 5.0]\n",
    "    \n",
    "    roi = auto_detect_title_region(video_path)\n",
    "    \n",
    "    best_config = None\n",
    "    best_slide_count = 0\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        for interval in intervals:\n",
    "            print(f\"\\\\nTesting: threshold={threshold}, interval={interval}s\")\n",
    "            \n",
    "            detector = SlideDetector(similarity_threshold=threshold, frame_interval=interval)\n",
    "            \n",
    "            # Process only first minute for testing\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            cap.release()\n",
    "            \n",
    "            # Create temporary shortened video processing\n",
    "            temp_detector = SlideDetector(similarity_threshold=threshold, frame_interval=interval)\n",
    "            \n",
    "            try:\n",
    "                # Quick test - process first few frames\n",
    "                cap = cv2.VideoCapture(video_path)\n",
    "                frame_count = 0\n",
    "                test_frames = int(fps * test_duration)  # Test first 60 seconds\n",
    "                previous_text = \"\"\n",
    "                slide_count = 0\n",
    "                \n",
    "                while frame_count < test_frames:\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_count)\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "                    \n",
    "                    current_text = temp_detector.extract_text_from_frame(frame, roi)\n",
    "                    \n",
    "                    if previous_text and len(current_text) > 10:\n",
    "                        similarity = temp_detector.calculate_text_similarity(previous_text, current_text)\n",
    "                        if similarity < threshold:\n",
    "                            slide_count += 1\n",
    "                    \n",
    "                    previous_text = current_text\n",
    "                    frame_count += int(fps * interval)\n",
    "                \n",
    "                cap.release()\n",
    "                \n",
    "                print(f\"  Detected {slide_count} slides in first {test_duration}s\")\n",
    "                \n",
    "                # Prefer configurations that detect a reasonable number of slides\n",
    "                if 2 <= slide_count <= 15 and slide_count > best_slide_count:\n",
    "                    best_slide_count = slide_count\n",
    "                    best_config = {'threshold': threshold, 'interval': interval}\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  Error: {e}\")\n",
    "    \n",
    "    if best_config:\n",
    "        print(f\"\\\\nüéØ Recommended settings:\")\n",
    "        print(f\"   similarity_threshold = {best_config['threshold']}\")\n",
    "        print(f\"   frame_interval = {best_config['interval']}\")\n",
    "        return best_config\n",
    "    else:\n",
    "        print(f\"\\\\n‚ö†Ô∏è  Could not determine optimal settings. Try manual adjustment.\")\n",
    "        return {'threshold': 0.7, 'interval': 3.0}\n",
    "\n",
    "# Test OCR setup\n",
    "print(\"Testing OCR setup...\")\n",
    "test_ocr_setup()\n",
    "\n",
    "# If you want to optimize settings for a specific video:\n",
    "# optimize_settings_for_video(\"your_video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd1487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTALLATION COMMANDS\n",
    "# Run these commands in your terminal/command prompt before using the tool:\n",
    "\n",
    "installation_commands = \"\"\"\n",
    "# Install required packages:\n",
    "pip install opencv-python\n",
    "pip install pytesseract  \n",
    "pip install Pillow\n",
    "pip install numpy\n",
    "\n",
    "# Install Tesseract OCR (Windows):\n",
    "# 1. Download from: https://github.com/UB-Mannheim/tesseract/wiki\n",
    "# 2. Run the installer (tesseract-ocr-w64-setup-5.3.x.exe)\n",
    "# 3. Add to PATH or set the path manually in the code\n",
    "\n",
    "# For Linux (Ubuntu/Debian):\n",
    "# sudo apt install tesseract-ocr\n",
    "\n",
    "# For macOS:\n",
    "# brew install tesseract\n",
    "\"\"\"\n",
    "\n",
    "print(\"INSTALLATION INSTRUCTIONS:\")\n",
    "print(installation_commands)\n",
    "\n",
    "# Quick test to see if packages are available\n",
    "try:\n",
    "    import cv2\n",
    "    print(\"‚úÖ OpenCV imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå OpenCV not available: {e}\")\n",
    "\n",
    "try:\n",
    "    import pytesseract\n",
    "    print(\"‚úÖ pytesseract imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå pytesseract not available: {e}\")\n",
    "\n",
    "try:\n",
    "    from PIL import Image\n",
    "    print(\"‚úÖ Pillow imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Pillow not available: {e}\")\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(\"‚úÖ NumPy imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå NumPy not available: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
