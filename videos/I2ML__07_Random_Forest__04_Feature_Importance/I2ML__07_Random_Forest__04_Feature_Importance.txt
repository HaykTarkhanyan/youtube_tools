hello and welcome back to introduction to machine learning I'm lud bman and in this video I will present feature importance methods for random forests the basic goal will be to uh get a measure on how important different features are so here on the left hand side for example the features of the mcars data set and the higher value here means that this feature is very important so at the end of this uh video you should understand what the goal of feature importance is of course so enhancing interpretability of random forests and I will present two different methods of computing feature importance methods namely permutation feature importance and feature importance based on improvements in Split so we will start with the permutation feature importance a good thing about R forests is that it improves the predictive performance of those individual decision trees by combining them but the downside is that we lose interpretability feature importance tries to mitigate this problem the basic question that we ask ourselves in permutation feature importance is how much the performance decreases if a feature is removed or rendered useless so here in this visualization here we just ignore or delete the feature column length which is I hope okay as an intuition but the permutation feature importance doesn't really delete this column but it permutes the entries of this column the goal is to remove the associations between this feature and the target variable but to remain the marginal distribution of this feature length so what we will do is that we yeah randomly permute values of this column here which keeps the margin distribution as it was before and then we can obtain an estimate or generalization error of this random forest with the permuted features and without permuting the features by predicting OB data so it's efficiently it's very efficient to compute this feature importance during training because first we avoid training new models so imagine you really would delete the entire column length then the model you trained before is no longer valid so you have to train new models uh with one column less that's of course mutationally rather intensive and we can again use this o principle used those OB observations as test data points here you have the pseudo code and hopeful helpful visualization of this let's go through this algorithm together the very first thing you do is that you calculate the generalization error the OB generalization error using some set based metric or on the original data okay so before permuting anything you just take your data as you have it before and estimate the generalization error for this then the permutation starts so in the second so in the second step we iterate through all the features and let's say we just take one feature for now X1 for example then we do the following we ignore this third line for a second and I will come back to this uh later so we take feature x j for example Here length and we distort the feature Target relation by permuting XJ so what you see here from left to right is that the column length was permuted so the left hand side you have 10 11 19 14 on the right hand side 11 19 14 10 yeah but it's just this one column that gets permuted all the other features which you don't see and the target variable which banana is not permuted okay you just prute the First Column here of course you do this for all the bootstrap samples but yeah you basically commute the original data so the bootst samping is a step after that then you compute all the oob oob predictions for the permuted feature data so the fhe I subscript oob subscript P J okay so don't worry about all these subscripts here this just means that it's the predicted value for the I observation when permuting feature J okay it's just a prediction for this observation I you do for all n observations and arrange these these predictions in F head o o side J for the J feature and then with these predictions what you can do is you just compare the predictions with the True Values okay so for example here at the top you have on the yeah you just have these predictions here H for example so the OB o OB prediction for for this first tree would be would be no you do this of course for for all the trees as you have seen in the O era prediction junk and use some set based metric whichever you prefer to compare the true labels why with the predicted Target VAR Target values F had J to compute or to estimate some generalization error so then you have GE head of O OJ and in the next step you take the difference between this generalization error which kind of evaluates how good this model with a permuted feature performs on new unseen test data and compare it with what you have computed in the very first step the OB error of the data set without permuting any features okay and if you permute the features of course the model should get worse so the G this thing G head o BJ will be larger so you have a larger error so The Fad I fad sorry F I had J the estimated feature importances for feature J will be positive okay so far so good I hope let's now return to this third line here I said before I'll skip that for a moment the reason why we have to do this several or we have to do this several times first of all fact the reason why we do this is that it's a random process right so if you permute features if you do this several times the the concrete values after a permutation will be different so we can be more or less Lucky in these iterations and to to cancel out any Randomness going on we have to do this several times okay so not just once do this 100 times for example so this step here permutation of feature length has to be done not once but several times which means that you get not only one estimated feature importance for feature J but more of them let's say 100 okay and in the end you take all these 100 values and average over them to get a final feature permutation feature importance for feature J an alternative to permutation feature importance is impurity importance what happens here is that you add up all the improvements and splits will feature XJ is used how does that work let's say we take feature J okay then first of all we go through all the trained models B had M let's say we start with the first one here we find all splits which used XJ as splitting variable here we have two splits that used XJ for splitting and we extract the Improvement or the risk reduction for these splits so these plus plus I here mean that yeah plus plus I is a good uh Improvement Plus I is not is also okay but not that much and plus plus plus I is a very good Improvement okay so it's very handwave here this just stands for the fact that different splits can lead to different risk reductions or different improvements then we sum everything up do this for all the trees of course so in the end we add up all the improvements over all trees forgetting this feature importance of feature J some final remarks here so let's first of all compare the two Alternatives permutation feature importance and impurity based feature importance on the right hand side we have permutation feature importance you see the increase of the mean squared error for the mcars data set for all these features on the left hand side impurity importance using the jny impurity for the same data set for the same features and if you compare left to right right well more or less it's the same right not the values on the x-axis themselves but don't ever compare I don't know Genie impurity with permutation feature importancy absolute numbers doesn't make sense choose one of the feature importances and then compare those numbers that's okay but if you just look at the the relative importance let's say it's more or less the same so the order changes the first two features the first most important features seem to be disp and WT but then on the left hand side you have HP as third most important feature and c y l on the right hand side but then they come on fourth place so uh take home message here is basically they are not that that different okay um one one carat both methods are bias towards features with more levels so if you for example have categorical features with many categories uh they tend to get higher um feature importance values in both methods and small Outlook uh there are more advanced versions um and most of all these pration feature and impurity feature importance can be generalized were generalized uh with a total lecture on inter interpretable machine learning where we have a lot of uh sections here on the details of all these feature importance measures and also on other feature importance measures that have been proposed in the literature